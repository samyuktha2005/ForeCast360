{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2665cd-a922-4178-80d3-2cff2f00f9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp-5c\\AppData\\Local\\Temp\\ipykernel_9440\\2730235211.py:23: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "D:\\New folder\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "D:\\New folder\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 131ms/step - loss: 0.0050 - mae: 0.0423 - val_loss: 0.0011 - val_mae: 0.0260\n",
      "Epoch 2/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 146ms/step - loss: 6.4566e-04 - mae: 0.0193 - val_loss: 0.0010 - val_mae: 0.0262\n",
      "Epoch 3/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 137ms/step - loss: 4.6088e-04 - mae: 0.0161 - val_loss: 4.1746e-04 - val_mae: 0.0155\n",
      "Epoch 4/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 153ms/step - loss: 3.7972e-04 - mae: 0.0145 - val_loss: 3.8637e-04 - val_mae: 0.0145\n",
      "Epoch 5/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 146ms/step - loss: 3.3757e-04 - mae: 0.0136 - val_loss: 7.2546e-04 - val_mae: 0.0208\n",
      "Epoch 6/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 143ms/step - loss: 3.1932e-04 - mae: 0.0131 - val_loss: 0.0011 - val_mae: 0.0267\n",
      "Epoch 7/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 141ms/step - loss: 2.9732e-04 - mae: 0.0126 - val_loss: 5.8369e-04 - val_mae: 0.0190\n",
      "Epoch 8/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 146ms/step - loss: 2.8572e-04 - mae: 0.0123 - val_loss: 7.2240e-04 - val_mae: 0.0205\n",
      "Epoch 9/20\n",
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 153ms/step - loss: 2.7985e-04 - mae: 0.0121 - val_loss: 4.7951e-04 - val_mae: 0.0164\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - loss: 4.8572e-04 - mae: 0.0165\n",
      "LSTM Test MAE: 0.0145\n",
      "Moving Average Baseline MAE: 0.1338\n",
      "Linear Regression Baseline MAE: 0.0700\n",
      "\n",
      "Model Performance Comparison:\n",
      "LSTM Model MAE: 0.0145\n",
      "Moving Average Baseline MAE: 0.1338\n",
      "Linear Regression Baseline MAE: 0.0700\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"jena_climate_2009_2016.csv\")\n",
    "\n",
    "# Convert \"Date Time\" to datetime format\n",
    "df[\"Date Time\"] = pd.to_datetime(df[\"Date Time\"], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Fill missing values (forward fill method)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Downsample the dataset (taking every 6th row to get hourly readings)\n",
    "df_downsampled = df.iloc[::6, :].reset_index(drop=True)\n",
    "\n",
    "# Select key features\n",
    "selected_features = [\"p (mbar)\", \"T (degC)\", \"rh (%)\", \"wv (m/s)\"]\n",
    "\n",
    "# Remove outliers using z-score method\n",
    "df_downsampled = df_downsampled[(np.abs(zscore(df_downsampled[selected_features])) < 3).all(axis=1)]\n",
    "\n",
    "# Normalize selected features\n",
    "scaler = MinMaxScaler()\n",
    "df_downsampled[selected_features] = scaler.fit_transform(df_downsampled[selected_features])\n",
    "\n",
    "# Prepare sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length, 1])  # Predicting temperature (T (degC))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 144  # Using past 144 hours (~6 days) to predict the next step\n",
    "data = df_downsampled[selected_features].values\n",
    "X, y = create_sequences(data, sequence_length)\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# ==============================\n",
    "# Build LSTM Model with Bidirectional Layer\n",
    "# ==============================\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(100, return_sequences=True, input_shape=(sequence_length, len(selected_features)))),\n",
    "    Dropout(0.1),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.1),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "optimizer = Adam(learning_rate=0.001, decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae',  # Monitor validation MAE (mean absolute error)\n",
    "    patience=5,          # Stop training if no improvement for 5 epochs\n",
    "    restore_best_weights=True,  # Restore the best weights\n",
    "    mode='min'  # Minimize the validation MAE\n",
    ")\n",
    "\n",
    "# Train Model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=20,  # Set a high epoch limit, early stopping will stop it earlier\n",
    "    batch_size=32,  # Try a smaller batch size for better updates\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]  # Add EarlyStopping callback\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Evaluate Model\n",
    "# ==============================\n",
    "loss, lstm_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"LSTM Test MAE: {lstm_mae:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# BASELINE MODEL COMPARISON\n",
    "# ==============================\n",
    "\n",
    "# 1. Moving Average Baseline (Predicts next value as mean of last n values)\n",
    "y_pred_baseline = np.array([np.mean(y_train[-sequence_length:])] * len(y_test))\n",
    "baseline_mae = mean_absolute_error(y_test, y_pred_baseline)\n",
    "print(f\"Moving Average Baseline MAE: {baseline_mae:.4f}\")\n",
    "\n",
    "# 2. Linear Regression Baseline\n",
    "lr_model = LinearRegression()\n",
    "X_train_lr = np.mean(X_train, axis=1)  # Flatten time-series to single values\n",
    "X_test_lr = np.mean(X_test, axis=1)\n",
    "\n",
    "lr_model.fit(X_train_lr, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_lr)\n",
    "\n",
    "lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "print(f\"Linear Regression Baseline MAE: {lr_mae:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# COMPARISON RESULTS\n",
    "# ==============================\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(f\"LSTM Model MAE: {lstm_mae:.4f}\")\n",
    "print(f\"Moving Average Baseline MAE: {baseline_mae:.4f}\")\n",
    "print(f\"Linear Regression Baseline MAE: {lr_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3901bb-2189-4a3a-9bcf-efc3a5ebf1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp-5c\\AppData\\Local\\Temp\\ipykernel_20128\\3307507533.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "D:\\New folder\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - loss: 0.0195 - mae: 0.0934 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 2/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 44ms/step - loss: 0.0025 - mae: 0.0387 - val_loss: 0.0023 - val_mae: 0.0421\n",
      "Epoch 3/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 0.0017 - val_mae: 0.0358\n",
      "Epoch 4/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 43ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 5.1830e-04 - val_mae: 0.0166\n",
      "Epoch 5/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 4.6816e-04 - val_mae: 0.0166\n",
      "Epoch 6/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 43ms/step - loss: 9.1649e-04 - mae: 0.0228 - val_loss: 3.3486e-04 - val_mae: 0.0133\n",
      "Epoch 7/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - loss: 7.7465e-04 - mae: 0.0209 - val_loss: 3.2492e-04 - val_mae: 0.0129\n",
      "Epoch 8/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 44ms/step - loss: 6.8990e-04 - mae: 0.0197 - val_loss: 2.8002e-04 - val_mae: 0.0122\n",
      "Epoch 9/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - loss: 6.2371e-04 - mae: 0.0188 - val_loss: 2.8592e-04 - val_mae: 0.0122\n",
      "Epoch 10/10\n",
      "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - loss: 5.6663e-04 - mae: 0.0178 - val_loss: 2.8250e-04 - val_mae: 0.0124\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step\n",
      "Test MAE (RNN): 0.0124\n",
      "R² Score (RNN): 0.9890\n",
      "\n",
      "Model Performance Comparison:\n",
      "RNN Model MAE: 0.0124, R² Score: 0.9890\n",
      "Moving Average Baseline MAE: 0.1338\n",
      "Linear Regression Baseline MAE: 0.0700, R² Score: 0.7003\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import zscore\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ==============================\n",
    "# DATA LOADING & PREPROCESSING\n",
    "# ==============================\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"jena_climate_2009_2016.csv\")\n",
    "\n",
    "# Convert \"Date Time\" to datetime format\n",
    "df[\"Date Time\"] = pd.to_datetime(df[\"Date Time\"], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Fill missing values (forward fill method)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Downsample the dataset (taking every 6th row to get hourly readings)\n",
    "df_downsampled = df.iloc[::6, :].reset_index(drop=True)\n",
    "\n",
    "# Select key features\n",
    "selected_features = [\"p (mbar)\", \"T (degC)\", \"rh (%)\", \"wv (m/s)\"]\n",
    "\n",
    "# Remove outliers using z-score method\n",
    "df_downsampled = df_downsampled[(np.abs(zscore(df_downsampled[selected_features])) < 3).all(axis=1)]\n",
    "\n",
    "# Normalize selected features\n",
    "scaler = MinMaxScaler()\n",
    "df_downsampled[selected_features] = scaler.fit_transform(df_downsampled[selected_features])\n",
    "\n",
    "# ==============================\n",
    "# SEQUENCE CREATION FOR RNN\n",
    "# ==============================\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length, 1])  # Predicting temperature (T (degC))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 144  # Using past 144 hours (~6 days) to predict the next step\n",
    "data = df_downsampled[selected_features].values\n",
    "X, y = create_sequences(data, sequence_length)\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# ==============================\n",
    "# BUILDING & TRAINING RNN MODEL\n",
    "# ==============================\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(50, return_sequences=True, input_shape=(sequence_length, len(selected_features))),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "rnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train Model\n",
    "history_rnn = rnn_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred_rnn = rnn_model.predict(X_test)\n",
    "mae_rnn = mean_absolute_error(y_test, y_pred_rnn)\n",
    "r2_rnn = r2_score(y_test, y_pred_rnn)\n",
    "\n",
    "print(f\"Test MAE (RNN): {mae_rnn:.4f}\")\n",
    "print(f\"R² Score (RNN): {r2_rnn:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# BASELINE MODEL COMPARISON\n",
    "# ==============================\n",
    "\n",
    "# 1. Moving Average Baseline\n",
    "y_pred_baseline = np.array([np.mean(y_train[-sequence_length:])] * len(y_test))\n",
    "baseline_mae = mean_absolute_error(y_test, y_pred_baseline)\n",
    "\n",
    "# 2. Linear Regression Baseline\n",
    "lr_model = LinearRegression()\n",
    "X_train_lr = np.mean(X_train, axis=1)  # Flatten time-series to single values\n",
    "X_test_lr = np.mean(X_test, axis=1)\n",
    "\n",
    "lr_model.fit(X_train_lr, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_lr)\n",
    "\n",
    "lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "lr_r2 = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# ==============================\n",
    "# COMPARISON RESULTS\n",
    "# ==============================\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(f\"RNN Model MAE: {mae_rnn:.4f}, R² Score: {r2_rnn:.4f}\")\n",
    "print(f\"Moving Average Baseline MAE: {baseline_mae:.4f}\")\n",
    "print(f\"Linear Regression Baseline MAE: {lr_mae:.4f}, R² Score: {lr_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce4673da-352f-48a8-847e-ac5d2db0d017",
   "metadata": {},
   "source": [
    "Lower MAE → Better Predictions\n",
    "\n",
    "If LSTM MAE < RNN MAE, LSTM is more accurate.\n",
    "\n",
    "If RNN MAE < LSTM MAE, RNN is more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e75161f-8f3e-4636-a8ad-b760dcfb98ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook project_modelbuild.ipynb to script\n",
      "[NbConvertApp] Writing 8132 bytes to project_modelbuild.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script project_modelbuild.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb7eef-5643-4caa-9db2-e3304737ce6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
